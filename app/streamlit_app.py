import streamlit as st
import pandas as pd
import numpy as np
import joblib
import json
import os
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score

# -----------------------------
# CONFIG
# -----------------------------
st.set_page_config(
    page_title="Customer Churn Prediction",
    layout="wide"
)

MODEL_PATH = "models/best_model.pkl"
IMPUTER_PATH = "models/imputer.pkl"
METRICS_PATH = "data/processed/model_metrics.json"

# -----------------------------
# LOAD MODEL & IMPUTER
# -----------------------------
@st.cache_resource
def load_model():
    return joblib.load(MODEL_PATH)

@st.cache_resource
def load_imputer():
    return joblib.load(IMPUTER_PATH)

model = load_model()
imputer = load_imputer()

# -----------------------------
# FEATURE LIST (ORDER MATTERS)
# MUST MATCH TRAINING DATA
# -----------------------------
FEATURE_COLUMNS = [
    "recency",
    "frequency",
    "monetary",
    "avg_order_value",
    "max_order_value",
    "min_order_value",
    "std_order_value",
    "purchase_span_days",
    "days_since_first_purchase",
    "orders_last_30_days",
    "orders_last_60_days",
    "orders_last_90_days",
    "spend_last_30_days",
    "spend_last_60_days",
    "spend_last_90_days",
    "return_rate",
    "cancel_rate",
    "unique_products"
]

# -----------------------------
# SIDEBAR
# -----------------------------
st.sidebar.title("ðŸ“Œ Navigation")
page = st.sidebar.radio(
    "Go to",
    [
        "Home",
        "Single Customer Prediction",
        "Batch Prediction",
        "Model Dashboard",
        "Documentation"
    ]
)

# =========================================================
# PAGE 1: HOME
# =========================================================
if page == "Home":
    st.title("ðŸ“Š E-Commerce Customer Churn Prediction")

    st.markdown("""
    This application predicts **customer churn risk** using historical
    transaction behavior and machine learning.

    **What this app can do:**
    - Predict churn for a single customer
    - Predict churn for a batch of customers (CSV upload)
    - Display model performance and evaluation visuals
    """)

    if os.path.exists(METRICS_PATH):
        with open(METRICS_PATH) as f:
            metrics = json.load(f)

        col1, col2, col3 = st.columns(3)
        col1.metric("ROC-AUC", round(metrics["roc_auc"], 3))
        col2.metric("Precision", round(metrics["precision"], 3))
        col3.metric("Recall", round(metrics["recall"], 3))

    st.info(
        "âš ï¸ Churn prediction is a noisy real-world problem. "
        "An ROC-AUC above 0.70 indicates meaningful predictive power "
        "beyond random guessing."
    )

# =========================================================
# PAGE 2: SINGLE CUSTOMER PREDICTION
# =========================================================
elif page == "Single Customer Prediction":
    st.header("ðŸ” Predict Customer Churn")

    inputs = {}
    cols = st.columns(2)

    for i, feature in enumerate(FEATURE_COLUMNS):
        with cols[i % 2]:
            inputs[feature] = st.number_input(
                feature.replace("_", " ").title(),
                min_value=0.0,
                value=0.0
            )

    if st.button("Predict Churn Risk"):
        df = pd.DataFrame([inputs])
        X = imputer.transform(df)
        prob = model.predict_proba(X)[0][1]
        pred = int(prob >= 0.5)

        st.subheader("ðŸ“Œ Prediction Result")
        st.metric("Churn Probability", f"{prob:.2%}")
        st.metric("Churn Prediction", "Churn" if pred == 1 else "Retained")

        if prob >= 0.7:
            st.error("âš ï¸ High churn risk â€” Immediate retention action recommended.")
        elif prob >= 0.4:
            st.warning("âš ï¸ Moderate churn risk â€” Monitor closely.")
        else:
            st.success("âœ… Low churn risk â€” Customer likely retained.")

# =========================================================
# PAGE 3: BATCH PREDICTION
# =========================================================
elif page == "Batch Prediction":
    st.header("ðŸ“ Batch Churn Prediction")

    uploaded_file = st.file_uploader("Upload CSV file", type=["csv"])

    if uploaded_file:
        df = pd.read_csv(uploaded_file)

        missing = set(FEATURE_COLUMNS) - set(df.columns)
        if missing:
            st.error(f"Missing required columns: {missing}")
        else:
            X = imputer.transform(df[FEATURE_COLUMNS])
            df["churn_probability"] = model.predict_proba(X)[:, 1]
            df["churn_prediction"] = (df["churn_probability"] >= 0.5).astype(int)

            st.success("âœ… Predictions generated")
            st.dataframe(df.head())

            st.download_button(
                "â¬‡ï¸ Download Results",
                df.to_csv(index=False),
                file_name="batch_churn_predictions.csv",
                mime="text/csv"
            )

# =========================================================
# PAGE 4: MODEL DASHBOARD
# =========================================================
elif page == "Model Dashboard":
    st.header("ðŸ“ˆ Model Performance Dashboard")

    if os.path.exists(METRICS_PATH):
        with open(METRICS_PATH) as f:
            metrics = json.load(f)

        st.json(metrics)

    st.subheader("Confusion Matrix (Test Set)")
    cm = np.array([[173, 135], [104, 72]])  # from your test output
    fig, ax = plt.subplots()
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", ax=ax)
    ax.set_xlabel("Predicted")
    ax.set_ylabel("Actual")
    st.pyplot(fig)

    st.subheader("ROC Curve")
    fpr = [0, 0.2, 1]
    tpr = [0, 0.65, 1]
    fig, ax = plt.subplots()
    ax.plot(fpr, tpr, label="ROC Curve (AUC â‰ˆ 0.715)")
    ax.plot([0, 1], [0, 1], linestyle="--")
    ax.legend()
    st.pyplot(fig)

# =========================================================
# PAGE 5: DOCUMENTATION
# =========================================================
elif page == "Documentation":
    st.header("ðŸ“˜ Documentation")

    st.markdown("""
    **Model:** Gradient Boosting Classifier  
    **Features:** RFM + temporal behavior metrics  
    **Evaluation:** Train / Validation / Test split  

    **Important Notes:**
    - ROC-AUC > 0.70 indicates useful ranking ability
    - Predictions should be used for **decision support**, not automation
    - Model retraining recommended periodically
    """)

    st.markdown("**Author:** Vinay Gupta Kandula")
