{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8640be15-71dc-43ac-b8d5-2be5319226c8",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Phase 5: Advanced Modeling (Naïve Evaluation)\n",
    "\n",
    "⚠️ IMPORTANT MODEL VALIDITY WARNING ⚠️\n",
    "\n",
    "The results in this notebook show unrealistically high performance\n",
    "(ROC-AUC ≈ 1.0). This is caused by temporal data leakage due to:\n",
    "\n",
    "• Random train/test splitting\n",
    "• Features computed using future transaction information\n",
    "• No enforcement of churn label availability windows\n",
    "\n",
    "This notebook is intentionally retained to demonstrate:\n",
    "WHY naïve evaluation is dangerous in churn prediction.\n",
    "\n",
    "❗ These results are NOT used for final model selection ❗\n",
    "\n",
    "Temporal leakage is formally diagnosed and corrected in:\n",
    "- Notebook 06: Temporal Validation\n",
    "- Notebook 07: Rolling Cross-Validation\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "581052df-97c1-4637-9d3a-920a60caf51a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries loaded successfully\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_curve\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "print(\"Libraries loaded successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d9b1bcf-b228-49ab-9ef0-f1f0cd85a5c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (4312, 22)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerid</th>\n",
       "      <th>first_purchase</th>\n",
       "      <th>last_purchase</th>\n",
       "      <th>frequency</th>\n",
       "      <th>total_transactions</th>\n",
       "      <th>monetary_value</th>\n",
       "      <th>avg_order_value</th>\n",
       "      <th>total_quantity</th>\n",
       "      <th>avg_quantity_per_txn</th>\n",
       "      <th>unique_products</th>\n",
       "      <th>unique_invoices</th>\n",
       "      <th>min_price</th>\n",
       "      <th>max_price</th>\n",
       "      <th>avg_price</th>\n",
       "      <th>price_std</th>\n",
       "      <th>country_count</th>\n",
       "      <th>recency_days</th>\n",
       "      <th>customer_tenure_days</th>\n",
       "      <th>days_since_first_purchase</th>\n",
       "      <th>days_since_last_purchase</th>\n",
       "      <th>avg_days_between_purchases</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12346.0</td>\n",
       "      <td>2009-12-14 08:34:00</td>\n",
       "      <td>2010-06-28 13:53:00</td>\n",
       "      <td>11</td>\n",
       "      <td>33</td>\n",
       "      <td>206.36</td>\n",
       "      <td>6.253333</td>\n",
       "      <td>70</td>\n",
       "      <td>2.121212</td>\n",
       "      <td>26</td>\n",
       "      <td>11</td>\n",
       "      <td>1.00</td>\n",
       "      <td>7.49</td>\n",
       "      <td>6.253333</td>\n",
       "      <td>1.682971</td>\n",
       "      <td>1</td>\n",
       "      <td>164</td>\n",
       "      <td>196</td>\n",
       "      <td>360</td>\n",
       "      <td>164</td>\n",
       "      <td>17.818182</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12347.0</td>\n",
       "      <td>2010-10-31 14:20:00</td>\n",
       "      <td>2010-12-07 14:57:00</td>\n",
       "      <td>2</td>\n",
       "      <td>71</td>\n",
       "      <td>162.95</td>\n",
       "      <td>2.295070</td>\n",
       "      <td>828</td>\n",
       "      <td>11.661972</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.75</td>\n",
       "      <td>2.295070</td>\n",
       "      <td>1.869887</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>39</td>\n",
       "      <td>2</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12348.0</td>\n",
       "      <td>2010-09-27 14:59:00</td>\n",
       "      <td>2010-09-27 14:59:00</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>14.39</td>\n",
       "      <td>0.719500</td>\n",
       "      <td>373</td>\n",
       "      <td>18.650000</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.45</td>\n",
       "      <td>0.719500</td>\n",
       "      <td>0.431856</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>73</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12349.0</td>\n",
       "      <td>2010-04-29 13:20:00</td>\n",
       "      <td>2010-10-28 08:23:00</td>\n",
       "      <td>3</td>\n",
       "      <td>102</td>\n",
       "      <td>875.34</td>\n",
       "      <td>8.581765</td>\n",
       "      <td>993</td>\n",
       "      <td>9.735294</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>0.42</td>\n",
       "      <td>250.00</td>\n",
       "      <td>8.581765</td>\n",
       "      <td>31.299379</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>181</td>\n",
       "      <td>224</td>\n",
       "      <td>42</td>\n",
       "      <td>60.333333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12351.0</td>\n",
       "      <td>2010-11-29 15:23:00</td>\n",
       "      <td>2010-11-29 15:23:00</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>49.46</td>\n",
       "      <td>2.355238</td>\n",
       "      <td>261</td>\n",
       "      <td>12.428571</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0.42</td>\n",
       "      <td>12.75</td>\n",
       "      <td>2.355238</td>\n",
       "      <td>2.735753</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customerid       first_purchase        last_purchase  frequency  \\\n",
       "0     12346.0  2009-12-14 08:34:00  2010-06-28 13:53:00         11   \n",
       "1     12347.0  2010-10-31 14:20:00  2010-12-07 14:57:00          2   \n",
       "2     12348.0  2010-09-27 14:59:00  2010-09-27 14:59:00          1   \n",
       "3     12349.0  2010-04-29 13:20:00  2010-10-28 08:23:00          3   \n",
       "4     12351.0  2010-11-29 15:23:00  2010-11-29 15:23:00          1   \n",
       "\n",
       "   total_transactions  monetary_value  avg_order_value  total_quantity  \\\n",
       "0                  33          206.36         6.253333              70   \n",
       "1                  71          162.95         2.295070             828   \n",
       "2                  20           14.39         0.719500             373   \n",
       "3                 102          875.34         8.581765             993   \n",
       "4                  21           49.46         2.355238             261   \n",
       "\n",
       "   avg_quantity_per_txn  unique_products  unique_invoices  min_price  \\\n",
       "0              2.121212               26               11       1.00   \n",
       "1             11.661972               70                2       0.38   \n",
       "2             18.650000               20                1       0.29   \n",
       "3              9.735294               90                3       0.42   \n",
       "4             12.428571               21                1       0.42   \n",
       "\n",
       "   max_price  avg_price  price_std  country_count  recency_days  \\\n",
       "0       7.49   6.253333   1.682971              1           164   \n",
       "1      12.75   2.295070   1.869887              1             2   \n",
       "2       1.45   0.719500   0.431856              1            73   \n",
       "3     250.00   8.581765  31.299379              1            42   \n",
       "4      12.75   2.355238   2.735753              1            10   \n",
       "\n",
       "   customer_tenure_days  days_since_first_purchase  days_since_last_purchase  \\\n",
       "0                   196                        360                       164   \n",
       "1                    37                         39                         2   \n",
       "2                     0                         73                        73   \n",
       "3                   181                        224                        42   \n",
       "4                     0                         10                        10   \n",
       "\n",
       "   avg_days_between_purchases  churn  \n",
       "0                   17.818182      1  \n",
       "1                   18.500000      0  \n",
       "2                    0.000000      0  \n",
       "3                   60.333333      0  \n",
       "4                    0.000000      0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/processed/customer_features.csv\")\n",
    "\n",
    "print(f\"Dataset Shape: {df.shape}\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9d46a88-29fd-490e-9a35-add490f73a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix shape: (4312, 18)\n",
      "Churn distribution:\n",
      "churn\n",
      "0    0.669\n",
      "1    0.331\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "drop_cols = [\n",
    "    \"customerid\",\n",
    "    \"first_purchase\",\n",
    "    \"last_purchase\",\n",
    "    \"churn\"\n",
    "]\n",
    "\n",
    "X = df.drop(columns=drop_cols)\n",
    "y = df[\"churn\"]\n",
    "\n",
    "print(\"Feature matrix shape:\", X.shape)\n",
    "print(\"Churn distribution:\")\n",
    "print(y.value_counts(normalize=True).round(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5aeea486-33fe-4b44-ab9b-e559f4d432b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 3018\n",
      "Test size: 1294\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.3,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Train size:\", X_train.shape[0])\n",
    "print(\"Test size:\", X_test.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "419e87b2-6abd-4139-a7e1-a873e1ce56c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d571cd0-4c09-4be8-a604-553d5038e6d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression ROC-AUC: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       866\n",
      "           1       0.99      1.00      1.00       428\n",
      "\n",
      "    accuracy                           1.00      1294\n",
      "   macro avg       1.00      1.00      1.00      1294\n",
      "weighted avg       1.00      1.00      1.00      1294\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_reg = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_prob_lr = log_reg.predict_proba(X_test_scaled)[:, 1]\n",
    "y_pred_lr = log_reg.predict(X_test_scaled)\n",
    "\n",
    "roc_lr = roc_auc_score(y_test, y_prob_lr)\n",
    "\n",
    "print(\"Logistic Regression ROC-AUC:\", round(roc_lr, 4))\n",
    "print(classification_report(y_test, y_pred_lr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d0099a1-aa8e-4f4b-b3e1-ecd1f6789328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree ROC-AUC: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       866\n",
      "           1       1.00      1.00      1.00       428\n",
      "\n",
      "    accuracy                           1.00      1294\n",
      "   macro avg       1.00      1.00      1.00      1294\n",
      "weighted avg       1.00      1.00      1.00      1294\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(\n",
    "    max_depth=6,\n",
    "    min_samples_split=20,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "dt_prob = dt.predict_proba(X_test)[:, 1]\n",
    "dt_pred = dt.predict(X_test)\n",
    "\n",
    "roc_dt = roc_auc_score(y_test, dt_prob)\n",
    "\n",
    "print(\"Decision Tree ROC-AUC:\", round(roc_dt, 4))\n",
    "print(classification_report(y_test, dt_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cab4692f-8237-41b4-8214-a6fa3fc1bf20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest ROC-AUC: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       866\n",
      "           1       1.00      1.00      1.00       428\n",
      "\n",
      "    accuracy                           1.00      1294\n",
      "   macro avg       1.00      1.00      1.00      1294\n",
      "weighted avg       1.00      1.00      1.00      1294\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=8,\n",
    "    min_samples_split=10,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "rf_prob = rf.predict_proba(X_test)[:, 1]\n",
    "rf_pred = rf.predict(X_test)\n",
    "\n",
    "roc_rf = roc_auc_score(y_test, rf_prob)\n",
    "\n",
    "print(\"Random Forest ROC-AUC:\", round(roc_rf, 4))\n",
    "print(classification_report(y_test, rf_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba908542-674f-4f5d-88ec-f24d2296122e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting ROC-AUC: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       866\n",
      "           1       1.00      1.00      1.00       428\n",
      "\n",
      "    accuracy                           1.00      1294\n",
      "   macro avg       1.00      1.00      1.00      1294\n",
      "weighted avg       1.00      1.00      1.00      1294\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier(\n",
    "    n_estimators=150,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=3,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "gb.fit(X_train, y_train)\n",
    "\n",
    "gb_prob = gb.predict_proba(X_test)[:, 1]\n",
    "gb_pred = gb.predict(X_test)\n",
    "\n",
    "roc_gb = roc_auc_score(y_test, gb_prob)\n",
    "\n",
    "print(\"Gradient Boosting ROC-AUC:\", round(roc_gb, 4))\n",
    "print(classification_report(y_test, gb_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b11d16ea-6a2f-4c02-a62f-419ff8e6900c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>ROC_AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  ROC_AUC\n",
       "0  Logistic Regression      1.0\n",
       "1        Decision Tree      1.0\n",
       "2        Random Forest      1.0\n",
       "3    Gradient Boosting      1.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({\n",
    "    \"Model\": [\n",
    "        \"Logistic Regression\",\n",
    "        \"Decision Tree\",\n",
    "        \"Random Forest\",\n",
    "        \"Gradient Boosting\"\n",
    "    ],\n",
    "    \"ROC_AUC\": [\n",
    "        round(roc_lr, 4),\n",
    "        round(roc_dt, 4),\n",
    "        round(roc_rf, 4),\n",
    "        round(roc_gb, 4)\n",
    "    ]\n",
    "})\n",
    "\n",
    "results.sort_values(\"ROC_AUC\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cbb816ca-c2dd-43b8-84e3-cada0ead56c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naïve models saved successfully\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "Path(\"../models\").mkdir(exist_ok=True)\n",
    "\n",
    "joblib.dump(log_reg, \"../models/logistic_regression_naive.pkl\")\n",
    "joblib.dump(dt, \"../models/decision_tree_naive.pkl\")\n",
    "joblib.dump(rf, \"../models/random_forest_naive.pkl\")\n",
    "joblib.dump(gb, \"../models/gradient_boosting_naive.pkl\")\n",
    "joblib.dump(scaler, \"../models/scaler_naive.pkl\")\n",
    "\n",
    "print(\"Naïve models saved successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e919841-be4e-40e8-9db9-6421a9715484",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Final Interpretation – Notebook 05\n",
    "\n",
    "All models achieved near-perfect ROC-AUC scores.\n",
    "\n",
    "These results are INVALID due to temporal data leakage caused by:\n",
    "• Random splitting of time-dependent customer behavior\n",
    "• Inclusion of features derived from future activity\n",
    "• No enforcement of churn observation windows\n",
    "\n",
    "This notebook demonstrates why naïve modeling is misleading.\n",
    "\n",
    "Temporal validation and leakage-safe evaluation are implemented in:\n",
    "- Notebook 06: Temporal Validation\n",
    "- Notebook 07: Rolling Cross-Validation\n",
    "\n",
    "Only leakage-corrected results are considered for final deployment.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dba7a23-671b-4b50-8f40-bfb53ca53c41",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "FINAL NOTE – MODEL VALIDITY (PHASE 5)\n",
    "\n",
    "All models achieve ROC-AUC ≈ 1.0 with perfect precision and recall.\n",
    "\n",
    "This performance is NOT realistic and is caused by:\n",
    "• Temporal data leakage\n",
    "• Random train/test splitting\n",
    "• Features derived using future transaction behavior\n",
    "\n",
    "These results are intentionally retained to demonstrate\n",
    "why naïve evaluation is dangerous in churn prediction.\n",
    "\n",
    "✔ This notebook fulfills Phase 5 (Model Development)\n",
    "❌ These models are NOT used for deployment\n",
    "\n",
    "Leakage-safe evaluation is performed in:\n",
    "- Notebook 06: Temporal Validation\n",
    "- Notebook 07: Rolling Cross-Validation\n",
    "\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
