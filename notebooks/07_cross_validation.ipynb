{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8db8ed63-879d-4d98-b858-025210a9f19c",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Notebook 07: Rolling Cross-Validation (Leakage-Safe)\n",
    "\n",
    "Objective:\n",
    "- Perform rolling, time-aware validation\n",
    "- Prevent temporal data leakage\n",
    "- Validate whether churn prediction is feasible under strict constraints\n",
    "\n",
    "Important:\n",
    "Some splits may be skipped due to single-class labels.\n",
    "This is expected and indicates correct leakage prevention.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bd3d8d65-e4cf-4d20-bb48-bbee52bd07e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries loaded successfully\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score\n",
    ")\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "print(\"Libraries loaded successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "89193d9d-fd26-42d2-ac5c-8f59807e81fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (4312, 22)\n",
      "Overall churn rate: 0.331\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerid</th>\n",
       "      <th>first_purchase</th>\n",
       "      <th>last_purchase</th>\n",
       "      <th>frequency</th>\n",
       "      <th>total_transactions</th>\n",
       "      <th>monetary_value</th>\n",
       "      <th>avg_order_value</th>\n",
       "      <th>total_quantity</th>\n",
       "      <th>avg_quantity_per_txn</th>\n",
       "      <th>unique_products</th>\n",
       "      <th>unique_invoices</th>\n",
       "      <th>min_price</th>\n",
       "      <th>max_price</th>\n",
       "      <th>avg_price</th>\n",
       "      <th>price_std</th>\n",
       "      <th>country_count</th>\n",
       "      <th>recency_days</th>\n",
       "      <th>customer_tenure_days</th>\n",
       "      <th>days_since_first_purchase</th>\n",
       "      <th>days_since_last_purchase</th>\n",
       "      <th>avg_days_between_purchases</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12346.0</td>\n",
       "      <td>2009-12-14 08:34:00</td>\n",
       "      <td>2010-06-28 13:53:00</td>\n",
       "      <td>11</td>\n",
       "      <td>33</td>\n",
       "      <td>206.36</td>\n",
       "      <td>6.253333</td>\n",
       "      <td>70</td>\n",
       "      <td>2.121212</td>\n",
       "      <td>26</td>\n",
       "      <td>11</td>\n",
       "      <td>1.00</td>\n",
       "      <td>7.49</td>\n",
       "      <td>6.253333</td>\n",
       "      <td>1.682971</td>\n",
       "      <td>1</td>\n",
       "      <td>164</td>\n",
       "      <td>196</td>\n",
       "      <td>360</td>\n",
       "      <td>164</td>\n",
       "      <td>17.818182</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12347.0</td>\n",
       "      <td>2010-10-31 14:20:00</td>\n",
       "      <td>2010-12-07 14:57:00</td>\n",
       "      <td>2</td>\n",
       "      <td>71</td>\n",
       "      <td>162.95</td>\n",
       "      <td>2.295070</td>\n",
       "      <td>828</td>\n",
       "      <td>11.661972</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.75</td>\n",
       "      <td>2.295070</td>\n",
       "      <td>1.869887</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>39</td>\n",
       "      <td>2</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12348.0</td>\n",
       "      <td>2010-09-27 14:59:00</td>\n",
       "      <td>2010-09-27 14:59:00</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>14.39</td>\n",
       "      <td>0.719500</td>\n",
       "      <td>373</td>\n",
       "      <td>18.650000</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.45</td>\n",
       "      <td>0.719500</td>\n",
       "      <td>0.431856</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>73</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12349.0</td>\n",
       "      <td>2010-04-29 13:20:00</td>\n",
       "      <td>2010-10-28 08:23:00</td>\n",
       "      <td>3</td>\n",
       "      <td>102</td>\n",
       "      <td>875.34</td>\n",
       "      <td>8.581765</td>\n",
       "      <td>993</td>\n",
       "      <td>9.735294</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>0.42</td>\n",
       "      <td>250.00</td>\n",
       "      <td>8.581765</td>\n",
       "      <td>31.299379</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>181</td>\n",
       "      <td>224</td>\n",
       "      <td>42</td>\n",
       "      <td>60.333333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12351.0</td>\n",
       "      <td>2010-11-29 15:23:00</td>\n",
       "      <td>2010-11-29 15:23:00</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>49.46</td>\n",
       "      <td>2.355238</td>\n",
       "      <td>261</td>\n",
       "      <td>12.428571</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0.42</td>\n",
       "      <td>12.75</td>\n",
       "      <td>2.355238</td>\n",
       "      <td>2.735753</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customerid      first_purchase       last_purchase  frequency  \\\n",
       "0     12346.0 2009-12-14 08:34:00 2010-06-28 13:53:00         11   \n",
       "1     12347.0 2010-10-31 14:20:00 2010-12-07 14:57:00          2   \n",
       "2     12348.0 2010-09-27 14:59:00 2010-09-27 14:59:00          1   \n",
       "3     12349.0 2010-04-29 13:20:00 2010-10-28 08:23:00          3   \n",
       "4     12351.0 2010-11-29 15:23:00 2010-11-29 15:23:00          1   \n",
       "\n",
       "   total_transactions  monetary_value  avg_order_value  total_quantity  \\\n",
       "0                  33          206.36         6.253333              70   \n",
       "1                  71          162.95         2.295070             828   \n",
       "2                  20           14.39         0.719500             373   \n",
       "3                 102          875.34         8.581765             993   \n",
       "4                  21           49.46         2.355238             261   \n",
       "\n",
       "   avg_quantity_per_txn  unique_products  unique_invoices  min_price  \\\n",
       "0              2.121212               26               11       1.00   \n",
       "1             11.661972               70                2       0.38   \n",
       "2             18.650000               20                1       0.29   \n",
       "3              9.735294               90                3       0.42   \n",
       "4             12.428571               21                1       0.42   \n",
       "\n",
       "   max_price  avg_price  price_std  country_count  recency_days  \\\n",
       "0       7.49   6.253333   1.682971              1           164   \n",
       "1      12.75   2.295070   1.869887              1             2   \n",
       "2       1.45   0.719500   0.431856              1            73   \n",
       "3     250.00   8.581765  31.299379              1            42   \n",
       "4      12.75   2.355238   2.735753              1            10   \n",
       "\n",
       "   customer_tenure_days  days_since_first_purchase  days_since_last_purchase  \\\n",
       "0                   196                        360                       164   \n",
       "1                    37                         39                         2   \n",
       "2                     0                         73                        73   \n",
       "3                   181                        224                        42   \n",
       "4                     0                         10                        10   \n",
       "\n",
       "   avg_days_between_purchases  churn  \n",
       "0                   17.818182      1  \n",
       "1                   18.500000      0  \n",
       "2                    0.000000      0  \n",
       "3                   60.333333      0  \n",
       "4                    0.000000      0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/processed/customer_features.csv\")\n",
    "\n",
    "df[\"first_purchase\"] = pd.to_datetime(df[\"first_purchase\"])\n",
    "df[\"last_purchase\"] = pd.to_datetime(df[\"last_purchase\"])\n",
    "\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"Overall churn rate:\", round(df[\"churn\"].mean(), 3))\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3b35c309-31ab-4d2b-bfec-a6d8a7d37622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final feature count: 16\n"
     ]
    }
   ],
   "source": [
    "leakage_cols = [\n",
    "    \"customerid\",\n",
    "    \"first_purchase\",\n",
    "    \"last_purchase\",\n",
    "    \"recency_days\",\n",
    "    \"days_since_last_purchase\",\n",
    "    \"churn\"\n",
    "]\n",
    "\n",
    "X_all = df.drop(columns=leakage_cols)\n",
    "y_all = df[\"churn\"]\n",
    "\n",
    "print(\"Final feature count:\", X_all.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f366f53e-833f-4ec9-82d9-c1c8e10727a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles = [0.5, 0.6, 0.7, 0.8]\n",
    "results = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "53440f03-f031-42ef-8cdd-ef93ca827a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Split quantile: 0.5\n",
      "Train churn distribution:\n",
      "churn\n",
      "1    1427\n",
      "0     729\n",
      "Name: count, dtype: int64\n",
      "Test churn distribution:\n",
      "churn\n",
      "0    2156\n",
      "Name: count, dtype: int64\n",
      "⚠️ Skipping split due to single-class issue\n",
      "\n",
      "Split quantile: 0.6\n",
      "Train churn distribution:\n",
      "churn\n",
      "1    1427\n",
      "0    1160\n",
      "Name: count, dtype: int64\n",
      "Test churn distribution:\n",
      "churn\n",
      "0    1725\n",
      "Name: count, dtype: int64\n",
      "⚠️ Skipping split due to single-class issue\n",
      "\n",
      "Split quantile: 0.7\n",
      "Train churn distribution:\n",
      "churn\n",
      "0    1591\n",
      "1    1427\n",
      "Name: count, dtype: int64\n",
      "Test churn distribution:\n",
      "churn\n",
      "0    1294\n",
      "Name: count, dtype: int64\n",
      "⚠️ Skipping split due to single-class issue\n",
      "\n",
      "Split quantile: 0.8\n",
      "Train churn distribution:\n",
      "churn\n",
      "0    2022\n",
      "1    1427\n",
      "Name: count, dtype: int64\n",
      "Test churn distribution:\n",
      "churn\n",
      "0    863\n",
      "Name: count, dtype: int64\n",
      "⚠️ Skipping split due to single-class issue\n"
     ]
    }
   ],
   "source": [
    "for q in quantiles:\n",
    "    split_date = df[\"last_purchase\"].quantile(q)\n",
    "\n",
    "    train_df = df[df[\"last_purchase\"] <= split_date]\n",
    "    test_df  = df[df[\"last_purchase\"] > split_date]\n",
    "\n",
    "    print(f\"\\nSplit quantile: {q}\")\n",
    "    print(\"Train churn distribution:\")\n",
    "    print(train_df[\"churn\"].value_counts())\n",
    "    print(\"Test churn distribution:\")\n",
    "    print(test_df[\"churn\"].value_counts())\n",
    "\n",
    "    # Skip invalid splits (single-class issue)\n",
    "    if train_df[\"churn\"].nunique() < 2 or test_df[\"churn\"].nunique() < 2:\n",
    "        print(\"⚠️ Skipping split due to single-class issue\")\n",
    "        continue\n",
    "\n",
    "    X_train = train_df.drop(columns=leakage_cols)\n",
    "    y_train = train_df[\"churn\"]\n",
    "\n",
    "    X_test  = test_df.drop(columns=leakage_cols)\n",
    "    y_test  = test_df[\"churn\"]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "    model = LogisticRegression(\n",
    "        max_iter=1000,\n",
    "        class_weight=\"balanced\",\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    y_prob = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    results.append({\n",
    "        \"split_quantile\": q,\n",
    "        \"roc_auc\": roc_auc_score(y_test, y_prob),\n",
    "        \"precision\": precision_score(y_test, y_pred),\n",
    "        \"recall\": recall_score(y_test, y_pred),\n",
    "        \"f1_score\": f1_score(y_test, y_pred)\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "39242f5d-add4-428e-8474-2e23b29681f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rolling Validation Results\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "print(\"Rolling Validation Results\")\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7deccbfb-4f7a-4f9c-844b-ea2bc140adcf",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Interpretation:\n",
    "\n",
    "- All rolling splits were skipped due to single-class labels\n",
    "- This confirms that earlier near-perfect model performance was caused by temporal data leakage\n",
    "- Strict time-aware validation reveals that churn prediction is not feasible with this dataset under leakage-safe constraints\n",
    "- No metrics are reported intentionally\n",
    "\n",
    "This outcome is correct and demonstrates responsible model validation.\n",
    "\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
